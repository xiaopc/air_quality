{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from database\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "con = create_engine('mysql+pymysql://root:toor@localhost:3306/air?charset=utf8')\n",
    "sql = \"select datehour, co, pm10, pm2_5, so2, o3, no2 from air_quality where location = '成都';\"\n",
    "\n",
    "dataset = pd.read_sql(sql, con, index_col='datehour')\n",
    "dataset['o3'].fillna(0, inplace = True)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               co   pm10  pm2_5   so2  o3   no2\n",
      "datehour                                       \n",
      "2014051300  1.168  190.0  133.0  15.0  79  51.0\n",
      "2014051301  1.265  210.0  151.0  16.0  68  57.0\n",
      "2014051302  1.321  215.0  159.0  17.0  47  68.0\n",
      "2014051303  1.393  238.0  178.0  17.0  32  78.0\n",
      "2014051304  1.437  259.0  196.0  17.0  31  75.0\n"
     ]
    }
   ],
   "source": [
    "# import from local csv\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('dataset.csv', index_col=0)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv for colab\n",
    "dataset.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define convert function\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "    # input sequence t-n -> t-1\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence t -> t+n\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # concat\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MinMaxScaler\n",
    "import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "scaler = joblib.load(scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27648, 456) (18432, 456)\n",
      "(27648, 576) (18432, 576)\n"
     ]
    }
   ],
   "source": [
    "# scale, convert, filter\n",
    "values = dataset.values.astype('float32')\n",
    "scaled = scaler.fit_transform(values) # num item normalize\n",
    "\n",
    "hours_back = 3 * 24\n",
    "hours_ahead = 24\n",
    "reframed = series_to_supervised(scaled, hours_back, hours_ahead)\n",
    "filtered_col = filter(lambda col : '-' not in col and 'var5' not in col, reframed.columns)\n",
    "reframed_filtered = reframed.copy()\n",
    "reframed_filtered.drop(list(filtered_col), axis=1, inplace=True)\n",
    "\n",
    "split_rate = 0.6\n",
    "batch_size = 128 * 8\n",
    "n_train_hours = int(reframed.shape[0] * split_rate / batch_size) * batch_size\n",
    "n_test_hours = int(reframed.shape[0] * (1 - split_rate) / batch_size) * batch_size\n",
    "train = reframed_filtered[:n_train_hours]\n",
    "# train = train.sample(frac=1)\n",
    "train = train.values\n",
    "test = reframed_filtered[-n_test_hours:].values\n",
    "\n",
    "train_unfiltered = reframed[:n_train_hours].values\n",
    "test_unfiltered = reframed[-n_test_hours:].values\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "print(train_unfiltered.shape, test_unfiltered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump MinMaxScaler\n",
    "import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape X, y =>  (27648, 72, 6) (27648, 24, 1)\n",
      " Testing data shape X, y =>  (18432, 72, 6) (18432, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "input_features = 6\n",
    "output_features = 1\n",
    "train_X, train_y = train[:, :-hours_ahead * output_features], train[:, -hours_ahead * output_features:]\n",
    "test_X, test_y = test[:, :-hours_ahead * output_features], test[:, -hours_ahead * output_features:]\n",
    "# [samples, timestamps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], hours_back, input_features))\n",
    "train_y = train_y.reshape((train_y.shape[0], hours_ahead, output_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], hours_back, input_features))\n",
    "test_y = test_y.reshape((test_y.shape[0], hours_ahead, output_features))\n",
    "print(\"Training data shape X, y => \",train_X.shape, train_y.shape)\n",
    "print(\" Testing data shape X, y => \", test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab only\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import RepeatVector, Concatenate, Activation, Dense, Dot, Lambda\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow import Variable\n",
    "# Define part of the attention layer gloablly so as to\n",
    "# share the same layers for each attention step.\n",
    "def softmax(x):\n",
    "    return K.softmax(x, axis=1)\n",
    "\n",
    "at_repeat = RepeatVector(train_X.shape[1])\n",
    "at_concatenate = Concatenate(axis=-1)\n",
    "at_dense1 = Dense(8, activation=\"tanh\")\n",
    "at_dense2 = Dense(1, activation=\"relu\")\n",
    "at_softmax = Activation(softmax, name='attention_weights')\n",
    "at_dot = Dot(axes=1)\n",
    "\n",
    "def one_step_of_attention(h_prev, a):\n",
    "    \"\"\"\n",
    "    Get the context.\n",
    "    \n",
    "    Input:\n",
    "    h_prev - Previous hidden state of a RNN layer (m, n_h)\n",
    "    a - Input data, possibly processed (m, Tx, n_a)\n",
    "    \n",
    "    Output:\n",
    "    context - Current context (m, Tx, n_a)\n",
    "    \"\"\"\n",
    "    # Repeat vector to match a's dimensions\n",
    "    h_repeat = at_repeat(h_prev)\n",
    "    # Calculate attention weights\n",
    "    i = at_concatenate([a, h_repeat])\n",
    "    i = at_dense1(i)\n",
    "    i = at_dense2(i)\n",
    "    attention = at_softmax(i)\n",
    "    # Calculate the context\n",
    "    context = at_dot([attention, a])\n",
    "    \n",
    "    return context\n",
    "\n",
    "def attention_layer(X, n_h, Ty):\n",
    "    \"\"\"\n",
    "    Creates an attention layer.\n",
    "    \n",
    "    Input:\n",
    "    X - Layer input (m, Tx, x_vocab_size)\n",
    "    n_h - Size of LSTM hidden layer\n",
    "    Ty - Timesteps in output sequence\n",
    "    \n",
    "    Output:\n",
    "    output - The output of the attention layer (m, Tx, n_h)\n",
    "    \"\"\"    \n",
    "    # Define the default state for the LSTM layer\n",
    "    h = Lambda(lambda X: K.zeros(shape=(K.shape(X)[0], n_h)))(X)\n",
    "    c = Lambda(lambda X: K.zeros(shape=(K.shape(X)[0], n_h)))(X)\n",
    "    # Messy, but the alternative is using more Input()\n",
    "    \n",
    "    at_LSTM = LSTM(n_h, return_state=True)\n",
    "    \n",
    "    output = []\n",
    "              \n",
    "    # Run attention step and RNN for each output time step\n",
    "    for _ in range(Ty):\n",
    "        context = one_step_of_attention(h, X)\n",
    "        \n",
    "        h, _, c = at_LSTM(context, initial_state=[h, c])\n",
    "        \n",
    "        output.append(h)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(1024, 72, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (1024, 40)           7520        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_14 (RepeatVector) (1024, 24, 40)       0           lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (1024, 24, 40)       12960       repeat_vector_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (1024, 24, 40)       0           lstm_15[0][0]                    \n",
      "                                                                 lstm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (1024, 24, 40)       0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (1024, 24, 1)        41          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,521\n",
      "Trainable params: 20,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining LSTM with 50 neurons in first hidden layer and 1 neuron in the o/p layer\n",
    "# using the MAE loss function and Adma version of stochastic gradient descent\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, TimeDistributed, RepeatVector, Dense, Dropout, Attention\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "def create_model():\n",
    "    x = Input(shape=(train_X.shape[1], train_X.shape[2]), batch_size=batch_size)    \n",
    "    encoder = LSTM(40, return_sequences=False)(x)\n",
    "    encoder = RepeatVector(hours_ahead)(encoder)\n",
    "    decoder = LSTM(40, return_sequences=True)(encoder)\n",
    "    qv_attention_seq = Attention()([decoder, decoder])\n",
    "    decoder = Dropout(0.3)(qv_attention_seq)\n",
    "    decoder = TimeDistributed(Dense(1, kernel_initializer='normal', activation='sigmoid'))(decoder)\n",
    "    model = Model(inputs=[x], outputs=[decoder])\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27648 samples, validate on 18432 samples\n",
      "Epoch 1/100\n",
      "27648/27648 - 18s - loss: 0.2581 - val_loss: 0.0985\n",
      "Epoch 2/100\n",
      "27648/27648 - 11s - loss: 0.1084 - val_loss: 0.0815\n",
      "Epoch 3/100\n",
      "27648/27648 - 11s - loss: 0.1038 - val_loss: 0.0802\n",
      "Epoch 4/100\n",
      "27648/27648 - 11s - loss: 0.1037 - val_loss: 0.0796\n",
      "Epoch 5/100\n",
      "27648/27648 - 11s - loss: 0.1038 - val_loss: 0.0796\n",
      "Epoch 6/100\n",
      "27648/27648 - 11s - loss: 0.1037 - val_loss: 0.0796\n",
      "Epoch 7/100\n",
      "27648/27648 - 11s - loss: 0.1038 - val_loss: 0.0796\n",
      "Epoch 8/100\n",
      "27648/27648 - 11s - loss: 0.1038 - val_loss: 0.0796\n",
      "Epoch 9/100\n",
      "27648/27648 - 11s - loss: 0.1037 - val_loss: 0.0796\n",
      "Epoch 10/100\n",
      "27648/27648 - 11s - loss: 0.1037 - val_loss: 0.0796\n",
      "Epoch 11/100\n",
      "27648/27648 - 11s - loss: 0.1036 - val_loss: 0.0796\n",
      "Epoch 12/100\n",
      "27648/27648 - 11s - loss: 0.1036 - val_loss: 0.0795\n",
      "Epoch 13/100\n",
      "27648/27648 - 11s - loss: 0.1036 - val_loss: 0.0795\n",
      "Epoch 14/100\n",
      "27648/27648 - 11s - loss: 0.1035 - val_loss: 0.0794\n",
      "Epoch 15/100\n",
      "27648/27648 - 12s - loss: 0.1035 - val_loss: 0.0792\n",
      "Epoch 16/100\n",
      "27648/27648 - 12s - loss: 0.1034 - val_loss: 0.0790\n",
      "Epoch 17/100\n",
      "27648/27648 - 11s - loss: 0.1031 - val_loss: 0.0785\n",
      "Epoch 18/100\n",
      "27648/27648 - 11s - loss: 0.1031 - val_loss: 0.0783\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-be45b221e78e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     verbose=2, shuffle=False)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# callbacks=[TensorBoard(log_dir='./log')]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py-keras-tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training with CPU\n",
    "history = model.fit(train_X, train_y, \n",
    "                    epochs=100, batch_size=batch_size, \n",
    "                    validation_data=(test_X, test_y), \n",
    "                    verbose=2, shuffle=False)\n",
    "# callbacks=[TensorBoard(log_dir='./log')]\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab TPU\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_host(resolver.master())\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    history = model.fit(train_X, train_y, \n",
    "                    epochs=100, batch_size=128, \n",
    "                    validation_data=(test_X, test_y), \n",
    "                    verbose=2, shuffle=False)\n",
    "    model.save('tpu_model.h5')\n",
    "# tpu_model.evaluate(test_X, test_y, batch_size=128 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# tracking history for plots\n",
    "pyplot.plot(history.history['loss'], 'b', label='training history')\n",
    "pyplot.plot(history.history['val_loss'],  'r',label='testing history')\n",
    "pyplot.title(\"Train and Test Loss for the LSTM\")\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
