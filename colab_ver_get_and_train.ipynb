{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "get_and_train.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlqn-E7hscMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import from database\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "con = create_engine('mysql+pymysql://root:toor@localhost:3306/air?charset=utf8')\n",
        "sql = \"select datehour, co, pm10, pm2_5, so2, o3, no2 from air_quality where location = '成都';\"\n",
        "\n",
        "dataset = pd.read_sql(sql, con, index_col='datehour')\n",
        "dataset['o3'].fillna(0, inplace = True)\n",
        "print(dataset.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoVAPpkHscMe",
        "colab_type": "code",
        "outputId": "853c09fb-78fc-4e55-cf33-8f13dd9ae236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# import from local csv\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('dataset.csv', index_col=0)\n",
        "print(dataset.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               co   pm10  pm2_5   so2  o3   no2\n",
            "datehour                                       \n",
            "2014051300  1.168  190.0  133.0  15.0  79  51.0\n",
            "2014051301  1.265  210.0  151.0  16.0  68  57.0\n",
            "2014051302  1.321  215.0  159.0  17.0  47  68.0\n",
            "2014051303  1.393  238.0  178.0  17.0  32  78.0\n",
            "2014051304  1.437  259.0  196.0  17.0  31  75.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UADAnwpMscMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output csv for colab\n",
        "dataset.to_csv('dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yZFVbkRscMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define convert function\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "    # input sequence t-n -> t-1\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence t -> t+n\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # concat\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Zx8iSVscMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load MinMaxScaler\n",
        "import joblib\n",
        "scaler_filename = \"scaler.save\"\n",
        "scaler = joblib.load(scaler_filename) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0KeYO98scM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzoy3Y2lscM6",
        "colab_type": "code",
        "outputId": "dacc3601-8dd0-43f7-b271-75f5255edbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# scale, convert, filter, split\n",
        "values = dataset.values.astype('float32')\n",
        "scaled = scaler.fit_transform(values) # num item normalize\n",
        "\n",
        "hours_back = 3 * 24\n",
        "hours_ahead = 24\n",
        "reframed = series_to_supervised(scaled, hours_back, hours_ahead)\n",
        "filtered_col = filter(lambda col : '-' not in col and 'var5' not in col, reframed.columns)\n",
        "reframed_filtered = reframed.copy()\n",
        "reframed_filtered.drop(list(filtered_col), axis=1, inplace=True)\n",
        "\n",
        "split_rate = 0.6\n",
        "batch_size = 128 * 8\n",
        "n_train_hours = int(reframed.shape[0] * split_rate / batch_size) * batch_size\n",
        "n_test_hours = int(reframed.shape[0] * (1 - split_rate) / batch_size) * batch_size\n",
        "train = reframed_filtered[:n_train_hours]\n",
        "# train = train.sample(frac=1)\n",
        "train = train.values\n",
        "test = reframed_filtered[-n_test_hours:].values\n",
        "\n",
        "train_unfiltered = reframed[:n_train_hours].values\n",
        "test_unfiltered = reframed[-n_test_hours:].values\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "print(train_unfiltered.shape, test_unfiltered.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27648, 456) (18432, 456)\n",
            "(27648, 576) (18432, 576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BnFpab7scM_",
        "colab_type": "code",
        "outputId": "ec8e50fd-d1c5-45eb-d0d9-f3ab383883b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# dump MinMaxScaler\n",
        "import joblib\n",
        "scaler_filename = \"scaler.save\"\n",
        "joblib.dump(scaler, scaler_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.save']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmxdsMe7scND",
        "colab_type": "code",
        "outputId": "bbae1060-2b28-42b4-94c2-ad0cbbbf7b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# split into input and outputs, and reshape\n",
        "input_features = 6\n",
        "output_features = 1\n",
        "train_X, train_y = train[:, :-hours_ahead * output_features], train[:, -hours_ahead * output_features:]\n",
        "test_X, test_y = test[:, :-hours_ahead * output_features], test[:, -hours_ahead * output_features:]\n",
        "# [samples, timestamps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], hours_back, input_features))\n",
        "train_y = train_y.reshape((train_y.shape[0], hours_ahead, output_features))\n",
        "test_X = test_X.reshape((test_X.shape[0], hours_back, input_features))\n",
        "test_y = test_y.reshape((test_y.shape[0], hours_ahead, output_features))\n",
        "print(\"Training data shape X, y => \",train_X.shape, train_y.shape)\n",
        "print(\" Testing data shape X, y => \", test_X.shape, test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape X, y =>  (27648, 72, 6) (27648, 24, 1)\n",
            " Testing data shape X, y =>  (18432, 72, 6) (18432, 24, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz6f085kscNG",
        "colab_type": "code",
        "outputId": "46741042-6d1d-4d76-ed94-28ea4984033d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For Colab only\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKoujV4GscNL",
        "colab_type": "code",
        "outputId": "0e72eeff-78a6-420a-a050-64a35028b0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# defining LSTM with 50 neurons in first hidden layer and 1 neuron in the o/p layer\n",
        "# using the MAE loss function and Adma version of stochastic gradient descent\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Layer, Bidirectional, LSTM, TimeDistributed, RepeatVector, Dense, Dropout, multiply\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attention_weights = self.add_weight(name='attention_weights',\n",
        "            shape=(input_shape[-1], ),\n",
        "            initializer='uniform',\n",
        "            trainable=True)\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        ai = K.exp(K.tanh(K.dot(x, self.attention_weights)))\n",
        "        weights = ai / K.sum(ai, axis=1).dimshuffle(0,'x')\n",
        "        \n",
        "        weighted_input = x * weights.dimshuffle(0, 1, 'x')\n",
        "        return weighted_input.sum(axis=1)\n",
        "        # return multiply([x, K.softmax(K.dot(x, self.attention_weights))])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(40, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False))\n",
        "    model.add(RepeatVector(hours_ahead))\n",
        "    # model.add(AttentionDecoder(40, train_X.shape[2]))\n",
        "    # model.add(attention_3d_block())\n",
        "    model.add(Bidirectional(LSTM(40, return_sequences=True)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(TimeDistributed(Dense(1, kernel_initializer='normal', activation='sigmoid')))\n",
        "    model.compile(loss='mae', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 40)                7520      \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 24, 40)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 24, 80)            25920     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 80)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 24, 1)             81        \n",
            "=================================================================\n",
            "Total params: 33,521\n",
            "Trainable params: 33,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kriw7WsQscNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training with CPU\n",
        "history = model.fit(train_X, train_y, \n",
        "                    epochs=100, batch_size=batch_size, \n",
        "                    validation_data=(test_X, test_y), \n",
        "                    verbose=2, shuffle=False)\n",
        "# callbacks=[TensorBoard(log_dir='./log')]\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnGEoYdSscNU",
        "colab_type": "code",
        "outputId": "f29a7854-8bf6-48f6-e166-dce91de55937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# For Colab TPU\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_host(resolver.master())\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "    history = model.fit(train_X, train_y, \n",
        "                    epochs=100, batch_size=batch_size, \n",
        "                    validation_data=(test_X, test_y), \n",
        "                    verbose=2, shuffle=True)\n",
        "    model.save('tpu_model.h5')\n",
        "# tpu_model.evaluate(test_X, test_y, batch_size=128 * 8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.66.67.90:8470\n",
            "INFO:tensorflow:Clearing out eager caches\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Epoch 1/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 0\n",
            "18/18 [==============================] - 1s 59ms/step\n",
            "27/27 - 5s - loss: 0.2127 - val_loss: 0.0889\n",
            "Epoch 2/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 1\n",
            "18/18 [==============================] - 1s 66ms/step\n",
            "27/27 - 3s - loss: 0.1043 - val_loss: 0.0816\n",
            "Epoch 3/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 2\n",
            "18/18 [==============================] - 1s 75ms/step\n",
            "27/27 - 4s - loss: 0.1042 - val_loss: 0.0811\n",
            "Epoch 4/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 3\n",
            "18/18 [==============================] - 1s 74ms/step\n",
            "27/27 - 4s - loss: 0.1035 - val_loss: 0.0807\n",
            "Epoch 5/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 4\n",
            "18/18 [==============================] - 2s 84ms/step\n",
            "27/27 - 5s - loss: 0.1031 - val_loss: 0.0802\n",
            "Epoch 6/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 5\n",
            "18/18 [==============================] - 2s 97ms/step\n",
            "27/27 - 5s - loss: 0.1025 - val_loss: 0.0807\n",
            "Epoch 7/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 6\n",
            "18/18 [==============================] - 2s 109ms/step\n",
            "27/27 - 6s - loss: 0.1023 - val_loss: 0.0809\n",
            "Epoch 8/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 7\n",
            "18/18 [==============================] - 2s 122ms/step\n",
            "27/27 - 6s - loss: 0.1019 - val_loss: 0.0813\n",
            "Epoch 9/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 8\n",
            "18/18 [==============================] - 2s 131ms/step\n",
            "27/27 - 7s - loss: 0.1005 - val_loss: 0.0797\n",
            "Epoch 10/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 9\n",
            "18/18 [==============================] - 3s 154ms/step\n",
            "27/27 - 8s - loss: 0.0975 - val_loss: 0.0777\n",
            "Epoch 11/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 10\n",
            "18/18 [==============================] - 3s 159ms/step\n",
            "27/27 - 9s - loss: 0.0929 - val_loss: 0.0733\n",
            "Epoch 12/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 11\n",
            "18/18 [==============================] - 3s 177ms/step\n",
            "27/27 - 10s - loss: 0.0891 - val_loss: 0.0692\n",
            "Epoch 13/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 12\n",
            "18/18 [==============================] - 3s 194ms/step\n",
            "27/27 - 10s - loss: 0.0872 - val_loss: 0.0683\n",
            "Epoch 14/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 13\n",
            "18/18 [==============================] - 4s 216ms/step\n",
            "27/27 - 11s - loss: 0.0868 - val_loss: 0.0671\n",
            "Epoch 15/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 14\n",
            "18/18 [==============================] - 4s 230ms/step\n",
            "27/27 - 12s - loss: 0.0862 - val_loss: 0.0676\n",
            "Epoch 16/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 15\n",
            "18/18 [==============================] - 5s 258ms/step\n",
            "27/27 - 13s - loss: 0.0860 - val_loss: 0.0667\n",
            "Epoch 17/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 16\n",
            "18/18 [==============================] - 5s 263ms/step\n",
            "27/27 - 14s - loss: 0.0858 - val_loss: 0.0673\n",
            "Epoch 18/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 17\n",
            "18/18 [==============================] - 5s 303ms/step\n",
            "27/27 - 16s - loss: 0.0857 - val_loss: 0.0664\n",
            "Epoch 19/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 18\n",
            "18/18 [==============================] - 6s 329ms/step\n",
            "27/27 - 17s - loss: 0.0856 - val_loss: 0.0669\n",
            "Epoch 20/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 19\n",
            "18/18 [==============================] - 6s 353ms/step\n",
            "27/27 - 18s - loss: 0.0853 - val_loss: 0.0676\n",
            "Epoch 21/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 20\n",
            "18/18 [==============================] - 7s 369ms/step\n",
            "27/27 - 19s - loss: 0.0853 - val_loss: 0.0656\n",
            "Epoch 22/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 21\n",
            "18/18 [==============================] - 7s 396ms/step\n",
            "27/27 - 21s - loss: 0.0852 - val_loss: 0.0659\n",
            "Epoch 23/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 22\n",
            "18/18 [==============================] - 8s 424ms/step\n",
            "27/27 - 22s - loss: 0.0849 - val_loss: 0.0659\n",
            "Epoch 24/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 23\n",
            "18/18 [==============================] - 7s 415ms/step\n",
            "27/27 - 23s - loss: 0.0846 - val_loss: 0.0657\n",
            "Epoch 25/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 24\n",
            "18/18 [==============================] - 9s 483ms/step\n",
            "27/27 - 25s - loss: 0.0842 - val_loss: 0.0653\n",
            "Epoch 26/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 25\n",
            "18/18 [==============================] - 9s 503ms/step\n",
            "27/27 - 27s - loss: 0.0836 - val_loss: 0.0642\n",
            "Epoch 27/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 26\n",
            "18/18 [==============================] - 9s 496ms/step\n",
            "27/27 - 27s - loss: 0.0828 - val_loss: 0.0654\n",
            "Epoch 28/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 27\n",
            "18/18 [==============================] - 10s 555ms/step\n",
            "27/27 - 29s - loss: 0.0808 - val_loss: 0.0611\n",
            "Epoch 29/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 28\n",
            "18/18 [==============================] - 11s 592ms/step\n",
            "27/27 - 31s - loss: 0.0765 - val_loss: 0.0566\n",
            "Epoch 30/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 29\n",
            "18/18 [==============================] - 10s 581ms/step\n",
            "27/27 - 32s - loss: 0.0718 - val_loss: 0.0539\n",
            "Epoch 31/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 30\n",
            "18/18 [==============================] - 13s 706ms/step\n",
            "27/27 - 36s - loss: 0.0688 - val_loss: 0.0526\n",
            "Epoch 32/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 31\n",
            "18/18 [==============================] - 12s 688ms/step\n",
            "27/27 - 36s - loss: 0.0668 - val_loss: 0.0519\n",
            "Epoch 33/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 32\n",
            "18/18 [==============================] - 12s 678ms/step\n",
            "27/27 - 37s - loss: 0.0650 - val_loss: 0.0519\n",
            "Epoch 34/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 33\n",
            "18/18 [==============================] - 14s 750ms/step\n",
            "27/27 - 39s - loss: 0.0639 - val_loss: 0.0528\n",
            "Epoch 35/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 34\n",
            "18/18 [==============================] - 13s 743ms/step\n",
            "27/27 - 41s - loss: 0.0636 - val_loss: 0.0495\n",
            "Epoch 36/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 35\n",
            "18/18 [==============================] - 15s 820ms/step\n",
            "27/27 - 44s - loss: 0.0629 - val_loss: 0.0490\n",
            "Epoch 37/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 36\n",
            "18/18 [==============================] - 16s 863ms/step\n",
            "27/27 - 45s - loss: 0.0619 - val_loss: 0.0484\n",
            "Epoch 38/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 37\n",
            "18/18 [==============================] - 16s 891ms/step\n",
            "27/27 - 46s - loss: 0.0615 - val_loss: 0.0483\n",
            "Epoch 39/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 38\n",
            "18/18 [==============================] - 17s 939ms/step\n",
            "27/27 - 49s - loss: 0.0611 - val_loss: 0.0487\n",
            "Epoch 40/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 39\n",
            "18/18 [==============================] - 17s 917ms/step\n",
            "27/27 - 49s - loss: 0.0607 - val_loss: 0.0478\n",
            "Epoch 41/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 40\n",
            "18/18 [==============================] - 18s 981ms/step\n",
            "27/27 - 54s - loss: 0.0606 - val_loss: 0.0484\n",
            "Epoch 42/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 41\n",
            "18/18 [==============================] - 18s 1s/step\n",
            "27/27 - 54s - loss: 0.0604 - val_loss: 0.0472\n",
            "Epoch 43/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 42\n",
            "18/18 [==============================] - 20s 1s/step\n",
            "27/27 - 59s - loss: 0.0600 - val_loss: 0.0474\n",
            "Epoch 44/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 43\n",
            "18/18 [==============================] - 20s 1s/step\n",
            "27/27 - 59s - loss: 0.0597 - val_loss: 0.0477\n",
            "Epoch 45/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 44\n",
            "18/18 [==============================] - 22s 1s/step\n",
            "27/27 - 63s - loss: 0.0600 - val_loss: 0.0473\n",
            "Epoch 46/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 45\n",
            "18/18 [==============================] - 21s 1s/step\n",
            "27/27 - 64s - loss: 0.0593 - val_loss: 0.0472\n",
            "Epoch 47/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 46\n",
            "18/18 [==============================] - 22s 1s/step\n",
            "27/27 - 66s - loss: 0.0592 - val_loss: 0.0479\n",
            "Epoch 48/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 47\n",
            "18/18 [==============================] - 24s 1s/step\n",
            "27/27 - 69s - loss: 0.0593 - val_loss: 0.0469\n",
            "Epoch 49/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 48\n",
            "18/18 [==============================] - 24s 1s/step\n",
            "27/27 - 72s - loss: 0.0591 - val_loss: 0.0467\n",
            "Epoch 50/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 49\n",
            "18/18 [==============================] - 25s 1s/step\n",
            "27/27 - 74s - loss: 0.0590 - val_loss: 0.0474\n",
            "Epoch 51/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 50\n",
            "18/18 [==============================] - 26s 1s/step\n",
            "27/27 - 76s - loss: 0.0590 - val_loss: 0.0466\n",
            "Epoch 52/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 51\n",
            "18/18 [==============================] - 26s 1s/step\n",
            "27/27 - 78s - loss: 0.0588 - val_loss: 0.0476\n",
            "Epoch 53/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 52\n",
            "18/18 [==============================] - 28s 2s/step\n",
            "27/27 - 81s - loss: 0.0586 - val_loss: 0.0471\n",
            "Epoch 54/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 53\n",
            "18/18 [==============================] - 30s 2s/step\n",
            "27/27 - 84s - loss: 0.0587 - val_loss: 0.0470\n",
            "Epoch 55/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 54\n",
            "18/18 [==============================] - 31s 2s/step\n",
            "27/27 - 87s - loss: 0.0587 - val_loss: 0.0478\n",
            "Epoch 56/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 55\n",
            "18/18 [==============================] - 29s 2s/step\n",
            "27/27 - 88s - loss: 0.0591 - val_loss: 0.0483\n",
            "Epoch 57/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 56\n",
            "18/18 [==============================] - 31s 2s/step\n",
            "27/27 - 92s - loss: 0.0590 - val_loss: 0.0462\n",
            "Epoch 58/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 57\n",
            "18/18 [==============================] - 31s 2s/step\n",
            "27/27 - 95s - loss: 0.0586 - val_loss: 0.0459\n",
            "Epoch 59/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 58\n",
            "18/18 [==============================] - 33s 2s/step\n",
            "27/27 - 97s - loss: 0.0584 - val_loss: 0.0476\n",
            "Epoch 60/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 59\n",
            "18/18 [==============================] - 35s 2s/step\n",
            "27/27 - 101s - loss: 0.0583 - val_loss: 0.0467\n",
            "Epoch 61/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 60\n",
            "18/18 [==============================] - 36s 2s/step\n",
            "27/27 - 103s - loss: 0.0582 - val_loss: 0.0462\n",
            "Epoch 62/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 61\n",
            "18/18 [==============================] - 36s 2s/step\n",
            "27/27 - 105s - loss: 0.0581 - val_loss: 0.0463\n",
            "Epoch 63/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 62\n",
            "18/18 [==============================] - 37s 2s/step\n",
            "27/27 - 109s - loss: 0.0580 - val_loss: 0.0466\n",
            "Epoch 64/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 63\n",
            "18/18 [==============================] - 37s 2s/step\n",
            "27/27 - 110s - loss: 0.0579 - val_loss: 0.0464\n",
            "Epoch 65/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 64\n",
            "18/18 [==============================] - 39s 2s/step\n",
            "27/27 - 113s - loss: 0.0581 - val_loss: 0.0460\n",
            "Epoch 66/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 65\n",
            "18/18 [==============================] - 39s 2s/step\n",
            "27/27 - 116s - loss: 0.0579 - val_loss: 0.0456\n",
            "Epoch 67/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 66\n",
            "18/18 [==============================] - 42s 2s/step\n",
            "27/27 - 121s - loss: 0.0578 - val_loss: 0.0477\n",
            "Epoch 68/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 67\n",
            "18/18 [==============================] - 41s 2s/step\n",
            "27/27 - 122s - loss: 0.0578 - val_loss: 0.0457\n",
            "Epoch 69/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 68\n",
            "18/18 [==============================] - 44s 2s/step\n",
            "27/27 - 128s - loss: 0.0574 - val_loss: 0.0460\n",
            "Epoch 70/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 69\n",
            "18/18 [==============================] - 44s 2s/step\n",
            "27/27 - 129s - loss: 0.0575 - val_loss: 0.0458\n",
            "Epoch 71/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 70\n",
            "18/18 [==============================] - 46s 3s/step\n",
            "27/27 - 134s - loss: 0.0573 - val_loss: 0.0467\n",
            "Epoch 72/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 71\n",
            "18/18 [==============================] - 45s 2s/step\n",
            "27/27 - 134s - loss: 0.0577 - val_loss: 0.0471\n",
            "Epoch 73/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 72\n",
            "18/18 [==============================] - 48s 3s/step\n",
            "27/27 - 139s - loss: 0.0579 - val_loss: 0.0456\n",
            "Epoch 74/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 73\n",
            "18/18 [==============================] - 47s 3s/step\n",
            "27/27 - 141s - loss: 0.0574 - val_loss: 0.0451\n",
            "Epoch 75/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 74\n",
            "18/18 [==============================] - 50s 3s/step\n",
            "27/27 - 148s - loss: 0.0573 - val_loss: 0.0455\n",
            "Epoch 76/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 75\n",
            "18/18 [==============================] - 51s 3s/step\n",
            "27/27 - 149s - loss: 0.0576 - val_loss: 0.0454\n",
            "Epoch 77/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 76\n",
            "18/18 [==============================] - 54s 3s/step\n",
            "27/27 - 154s - loss: 0.0572 - val_loss: 0.0451\n",
            "Epoch 78/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 77\n",
            "18/18 [==============================] - 53s 3s/step\n",
            "27/27 - 157s - loss: 0.0572 - val_loss: 0.0460\n",
            "Epoch 79/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 78\n",
            "18/18 [==============================] - 55s 3s/step\n",
            "27/27 - 161s - loss: 0.0573 - val_loss: 0.0458\n",
            "Epoch 80/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 79\n",
            "18/18 [==============================] - 55s 3s/step\n",
            "27/27 - 161s - loss: 0.0572 - val_loss: 0.0460\n",
            "Epoch 81/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 80\n",
            "18/18 [==============================] - 58s 3s/step\n",
            "27/27 - 167s - loss: 0.0574 - val_loss: 0.0455\n",
            "Epoch 82/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 81\n",
            "18/18 [==============================] - 56s 3s/step\n",
            "27/27 - 168s - loss: 0.0572 - val_loss: 0.0463\n",
            "Epoch 83/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 82\n",
            "18/18 [==============================] - 60s 3s/step\n",
            "27/27 - 176s - loss: 0.0573 - val_loss: 0.0456\n",
            "Epoch 84/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 83\n",
            "18/18 [==============================] - 59s 3s/step\n",
            "27/27 - 177s - loss: 0.0572 - val_loss: 0.0451\n",
            "Epoch 85/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 84\n",
            "18/18 [==============================] - 62s 3s/step\n",
            "27/27 - 181s - loss: 0.0572 - val_loss: 0.0454\n",
            "Epoch 86/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 85\n",
            "18/18 [==============================] - 61s 3s/step\n",
            "27/27 - 183s - loss: 0.0573 - val_loss: 0.0452\n",
            "Epoch 87/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 86\n",
            "18/18 [==============================] - 63s 4s/step\n",
            "27/27 - 187s - loss: 0.0570 - val_loss: 0.0454\n",
            "Epoch 88/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 87\n",
            "18/18 [==============================] - 64s 4s/step\n",
            "27/27 - 190s - loss: 0.0569 - val_loss: 0.0452\n",
            "Epoch 89/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 88\n",
            "18/18 [==============================] - 65s 4s/step\n",
            "27/27 - 193s - loss: 0.0568 - val_loss: 0.0454\n",
            "Epoch 90/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 89\n",
            "18/18 [==============================] - 67s 4s/step\n",
            "27/27 - 201s - loss: 0.0567 - val_loss: 0.0452\n",
            "Epoch 91/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 90\n",
            "18/18 [==============================] - 70s 4s/step\n",
            "27/27 - 203s - loss: 0.0567 - val_loss: 0.0460\n",
            "Epoch 92/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 91\n",
            "18/18 [==============================] - 69s 4s/step\n",
            "27/27 - 205s - loss: 0.0568 - val_loss: 0.0462\n",
            "Epoch 93/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 92\n",
            "18/18 [==============================] - 70s 4s/step\n",
            "27/27 - 209s - loss: 0.0566 - val_loss: 0.0453\n",
            "Epoch 94/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 93\n",
            "18/18 [==============================] - 71s 4s/step\n",
            "27/27 - 212s - loss: 0.0567 - val_loss: 0.0453\n",
            "Epoch 95/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 94\n",
            "18/18 [==============================] - 75s 4s/step\n",
            "27/27 - 222s - loss: 0.0565 - val_loss: 0.0455\n",
            "Epoch 96/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 95\n",
            "18/18 [==============================] - 73s 4s/step\n",
            "27/27 - 224s - loss: 0.0567 - val_loss: 0.0448\n",
            "Epoch 97/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 96\n",
            "18/18 [==============================] - 79s 4s/step\n",
            "27/27 - 232s - loss: 0.0567 - val_loss: 0.0460\n",
            "Epoch 98/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 97\n",
            "18/18 [==============================] - 75s 4s/step\n",
            "27/27 - 230s - loss: 0.0565 - val_loss: 0.0451\n",
            "Epoch 99/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 98\n",
            "18/18 [==============================] - 79s 4s/step\n",
            "27/27 - 237s - loss: 0.0563 - val_loss: 0.0448\n",
            "Epoch 100/100\n",
            "INFO:tensorflow:Running validation at fit epoch: 99\n",
            "18/18 [==============================] - 81s 5s/step\n",
            "27/27 - 242s - loss: 0.0565 - val_loss: 0.0453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7_r6u7escNY",
        "colab_type": "code",
        "outputId": "c1a412cd-f197-436d-da10-d87b0abd16d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "\n",
        "# tracking history for plots\n",
        "pyplot.plot(history.history['loss'], 'b', label='training history')\n",
        "pyplot.plot(history.history['val_loss'],  'r',label='testing history')\n",
        "pyplot.title(\"Train and Test Loss for the LSTM\")\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}